

# üéå Clasificaci√≥n de Caracteres Japoneses con Redes Neuronales

Este proyecto aborda el desaf√≠o de **Reconocimiento √ìptico de Caracteres (OCR)** para la identificaci√≥n de caracteres japoneses antiguos (Kuzushiji). Se implementan y comparan dos enfoques arquitect√≥nicos: una **Red Neuronal construida desde cero (from scratch)** utilizando √∫nicamente NumPy, y una implementaci√≥n moderna utilizando **PyTorch**.

El objetivo es clasificar correctamente im√°genes de $28 \times 28$ p√≠xeles en 49 clases distintas, explorando el impacto de diversos hiperpar√°metros y t√©cnicas de optimizaci√≥n.

## üöÄ Caracter√≠sticas del Proyecto

El sistema no es solo una "caja negra", sino una exploraci√≥n profunda de los fundamentos del Deep Learning. Incluye:

  * **Implementaci√≥n "From Scratch" (`numpy`):**
      * Arquitectura MLP configurable (capas ocultas din√°micas).
      * Backpropagation manual.
      * Funciones de activaci√≥n (ReLU, Softmax).
      * Optimizador **Adam** implementado manualmente.
      * **Rate Scheduling** (Lineal con saturaci√≥n y Exponencial).
      * Regularizaci√≥n L2 y Early Stopping.
  * **Implementaci√≥n PyTorch:**
      * R√©plica de la arquitectura para validaci√≥n de resultados.
      * Uso de `torch.nn` y `torch.optim`.
  * **An√°lisis de Modelos:** Comparativa entre 5 modelos distintos (m0 a m4) variando desde configuraciones b√°sicas hasta redes con overfitting forzado.

## üõ†Ô∏è Tecnolog√≠as Utilizadas

  * **Python**: Lenguaje principal.
  * **NumPy**: C√°lculos matriciales y √°lgebra lineal para la red "from scratch".
  * **PyTorch**: Framework de Deep Learning para los modelos avanzados (m2, m3, m4).
  * **Matplotlib**: Visualizaci√≥n de curvas de p√©rdida (loss) y precisi√≥n (accuracy).
  * **Pandas**: Manejo de datos y generaci√≥n de archivos de salida.

## üìä Resultados Destacados

Basado en el informe t√©cnico adjunto, se evaluaron diferentes configuraciones:

| Modelo | Tipo | Configuraci√≥n | Accuracy (Val) | Observaci√≥n |
| :--- | :--- | :--- | :--- | :--- |
| **m0** | Scratch | B√°sico, SGD | \~56% | Baseline |
| **m1** | Scratch | Adam, L2, Early Stopping | \~63% | Mejoras significativas por optimizador |
| **m2** | PyTorch | R√©plica de m1 | \~63% | Validaci√≥n de la implementaci√≥n manual |
| **m3** | PyTorch | Grid Search [100, 80] | **\~63%** | Modelo seleccionado por mejor generalizaci√≥n |
| **m4** | PyTorch | Overfitting [5000] | \~70% | Alta varianza, poca generalizaci√≥n |

El modelo **m3** fue seleccionado para la inferencia final debido a su equilibrio entre precisi√≥n y capacidad de generalizaci√≥n, evitando el overfitting observado en redes masivas (m4).

## üë§ Autor

**Manuel Borrell**
*Ingenier√≠a en Inteligencia Artificial - Universidad de San Andr√©s*

-----

*Este proyecto fue desarrollado como parte del curso de Aprendizaje Autom√°tico y Aprendizaje Profundo.*
